
# ðŸ’¬ ChatGPT + Gradio Integration

This project demonstrates how to integrate **ChatGPT** with a **Gradio** interface using a custom model endpoint and API key. It supports both **CLI interaction** and a **web-based UI** for chatting with a language model.

## ðŸš€ Features

* ðŸŒ **Gradio Web UI** for interactive chat
* ðŸ–¥ï¸ **Command-line Interface** for direct terminal chat
* âš™ï¸ Custom base URL support for self-hosted or proxy models
* ðŸ” Continuous loop in CLI for back-and-forth conversation

## ðŸ› ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

### 2. Install Dependencies

```bash
pip install openai gradio
```

### 3. Set Your Environment Variables

Set your API key and base URL in your system environment variables or directly in the script:

```python
api_key = "your_api_key_here"
base_url = "https://models.github.ai/inference"
```

### 4. Run the App

```bash
python app.py
```

* Visit the Gradio interface in your browser
* Or chat directly via terminal

---

## ðŸ§  Tech Stack

* **Python**
* **Gradio** â€“ for creating the web interface
* **OpenAI SDK** â€“ for calling the GPT model

---

## ðŸ“ Example Prompt

Ask anything like:

> "Explain the difference between machine learning and deep learning."

---


